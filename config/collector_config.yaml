default:
    trainer: ppo
    batch_size: 512
    num_update: 10
    beta: 1e-03
    buffer_size: 10240
    train_interval: 20
    epsilon: 0.28
    hidden_units: 16
    lambd: 0.99
    learning_rate: 0.005
    learning_rate_schedule: constant
    max_steps: 1e6
    memory_size: 16
    normalize: true
    num_epoch: 3
    num_layers: 2
    time_horizon: 512
    sequence_length: 24
    summary_freq: 5000
    use_recurrent: false
    vis_encode_type: simple #simple, nature_cnn, resnet
    reward_signals:
        extrinsic:
            strength: 1.0
            gamma: 0.99
        # curiosity:
            # strength: 0.015
            # gamma: 0.99
            # encoding_size: 128
        gail:
            strength: 0.75
            gamma: 0.99
            demo_path: C:\Users\joshu\Documents\GitHub\ResourceCollector\Assets\Demonstrations\ResourceCollector_6-4.demo
            
# SAC
# default:
    # trainer: sac
    # batch_size: 1024
    # num_update: 10
    # beta: 5.0e-3
    # buffer_size: 10240
    # buffer_init_steps: 5000
    # init_entcoef: 0.7
    # train_interval: 25
    # tau: 0.005
    # steps_per_update: 10
    # hidden_units: 32
    # learning_rate: 0.002
    # learning_rate_schedule: constant
    # max_steps: 2e6
    # memory_size: 16
    # normalize: true
    # num_layers: 1
    # time_horizon: 256
    # sequence_length: 24
    # summary_freq: 5000
    # use_recurrent: false
    # vis_encode_type: simple #simple, nature_cnn, resnet
    # reward_signals:
        # extrinsic:
            # strength: 1.0
            # gamma: 0.99
        # # curiosity:
            # # strength: 0.01
            # # gamma: 0.99
            # # encoding_size: 64
        # gail:
            # strength: 0.1
            # gamma: 0.99
            # demo_path: C:\Users\joshu\Documents\GitHub\ResourceCollector\Assets\Demonstrations\ResourceCollecto_14.demo

# default:
    # trainer: ppo
    # batch_size: 64
    # beta: 0.001
    # buffer_size: 8192
    # epsilon: 0.20
    # hidden_units: 64
    # lambd: 0.98
    # learning_rate: 0.008
    # learning_rate_schedule: linear
    # max_steps: 1.0e6
    # normalize: true
    # num_epoch: 3
    # num_layers: 2
    # time_horizon: 2048
    # summary_freq: 3000
    
    # # rnn
    # use_recurrent: false
    # sequence_length: 64
    # memory_size: 32
    
    # vis_encode_type: simple
    # reward_signals:
        # extrinsic:
            # strength: 1.0
            # gamma: 0.99
        # # curiosity:
           # # strength: 0.01
           # # gamma: 0.95
           # # encoding_size: 64
    
# working second agent -- 80k
# default:
    # trainer: ppo
    # batch_size: 64
    # beta: 0.006
    # buffer_size: 4098
    # epsilon: 0.285
    # hidden_units: 96
    # lambd: 0.97 
    # learning_rate: 0.04
    # learning_rate_schedule: linear
    # max_steps: 2.0e5
    # memory_size: 32
    # normalize: false
    # num_epoch: 9
    # num_layers: 2
    # time_horizon: 512
    # sequence_length: 64
    # summary_freq: 2000
    # use_recurrent: false
    # vis_encode_type: simple
    # reward_signals:
        # extrinsic:
            # strength: 1.0
            # gamma: 0.99

# working first agent -- 200k
# default:
    # trainer: ppo
    # batch_size: 64
    # beta: 0.006
    # buffer_size: 4098
    # epsilon: 0.285
    # hidden_units: 96
    # lambd: 0.97 
    # learning_rate: 0.01
    # learning_rate_schedule: linear
    # max_steps: 2.0e5
    # memory_size: 32
    # normalize: false
    # num_epoch: 9
    # num_layers: 2
    # time_horizon: 256
    # sequence_length: 64
    # summary_freq: 2000
    # use_recurrent: false
    # vis_encode_type: simple
    # reward_signals:
        # extrinsic:
            # strength: 1.0
            # gamma: 0.99

FoodCollector:
    normalize: false
    beta: 5.0e-3
    batch_size: 1024
    buffer_size: 10240
    max_steps: 1.0e5

Bouncer:
    normalize: true
    max_steps: 1.0e6
    num_layers: 2
    hidden_units: 64

PushBlock:
    max_steps: 5.0e4
    batch_size: 128
    buffer_size: 2048
    beta: 1.0e-2
    hidden_units: 256
    summary_freq: 2000
    time_horizon: 64
    num_layers: 2

SmallWallJump:
    max_steps: 1.0e6
    batch_size: 128
    buffer_size: 2048
    beta: 5.0e-3
    hidden_units: 256
    summary_freq: 2000
    time_horizon: 128
    num_layers: 2
    normalize: false

BigWallJump:
    max_steps: 1.0e6
    batch_size: 128
    buffer_size: 2048
    beta: 5.0e-3
    hidden_units: 256
    summary_freq: 2000
    time_horizon: 128
    num_layers: 2
    normalize: false

Striker:
    max_steps: 5.0e5
    learning_rate: 1e-3
    batch_size: 128
    num_epoch: 3
    buffer_size: 2000
    beta: 1.0e-2
    hidden_units: 256
    summary_freq: 2000
    time_horizon: 128
    num_layers: 2
    normalize: false

Goalie:
    max_steps: 5.0e5
    learning_rate: 1e-3
    batch_size: 320
    num_epoch: 3
    buffer_size: 2000
    beta: 1.0e-2
    hidden_units: 256
    summary_freq: 2000
    time_horizon: 128
    num_layers: 2
    normalize: false

Pyramids:
    summary_freq: 2000
    time_horizon: 128
    batch_size: 128
    buffer_size: 2048
    hidden_units: 512
    num_layers: 2
    beta: 1.0e-2
    max_steps: 5.0e5
    num_epoch: 3
    reward_signals:
        extrinsic:
            strength: 1.0
            gamma: 0.99
        curiosity:
            strength: 0.02
            gamma: 0.99
            encoding_size: 256

VisualPyramids:
    time_horizon: 128
    batch_size: 64
    buffer_size: 2024
    hidden_units: 256
    num_layers: 1
    beta: 1.0e-2
    max_steps: 5.0e5
    num_epoch: 3
    reward_signals:
        extrinsic:
            strength: 1.0
            gamma: 0.99
        curiosity:
            strength: 0.01
            gamma: 0.99
            encoding_size: 256

3DBall:
    normalize: true
    batch_size: 64
    buffer_size: 12000
    summary_freq: 1000
    time_horizon: 1000
    lambd: 0.99
    beta: 0.001

3DBallHard:
    normalize: true
    batch_size: 1200
    buffer_size: 12000
    summary_freq: 1000
    time_horizon: 1000
    max_steps: 5.0e5
    beta: 0.001
    reward_signals:
        extrinsic:
            strength: 1.0
            gamma: 0.995

Tennis:
    normalize: true
    max_steps: 2e5

CrawlerStatic:
    normalize: true
    num_epoch: 3
    time_horizon: 1000
    batch_size: 2024
    buffer_size: 20240
    max_steps: 1e6
    summary_freq: 3000
    num_layers: 3
    hidden_units: 512
    reward_signals:
        extrinsic:
            strength: 1.0
            gamma: 0.995

CrawlerDynamic:
    normalize: true
    num_epoch: 3
    time_horizon: 1000
    batch_size: 2024
    buffer_size: 20240
    max_steps: 1e6
    summary_freq: 3000
    num_layers: 3
    hidden_units: 512
    reward_signals:
        extrinsic:
            strength: 1.0
            gamma: 0.995

Walker:
    normalize: true
    num_epoch: 3
    time_horizon: 1000
    batch_size: 2048
    buffer_size: 20480
    max_steps: 2e6
    summary_freq: 3000
    num_layers: 3
    hidden_units: 512
    reward_signals:
        extrinsic:
            strength: 1.0
            gamma: 0.995

Reacher:
    normalize: true
    num_epoch: 3
    time_horizon: 1000
    batch_size: 2024
    buffer_size: 20240
    max_steps: 1e6
    summary_freq: 3000
    reward_signals:
        extrinsic:
            strength: 1.0
            gamma: 0.995

Hallway:
    use_recurrent: true
    sequence_length: 64
    num_layers: 2
    hidden_units: 128
    memory_size: 256
    beta: 1.0e-2
    num_epoch: 3
    buffer_size: 1024
    batch_size: 128
    max_steps: 5.0e5
    summary_freq: 1000
    time_horizon: 64

VisualHallway:
    use_recurrent: true
    sequence_length: 64
    num_layers: 1
    hidden_units: 128
    memory_size: 256
    beta: 1.0e-2
    num_epoch: 3
    buffer_size: 1024
    batch_size: 64
    max_steps: 5.0e5
    summary_freq: 1000
    time_horizon: 64

VisualPushBlock:
    use_recurrent: true
    sequence_length: 32
    num_layers: 1
    hidden_units: 128
    memory_size: 256
    beta: 1.0e-2
    num_epoch: 3
    buffer_size: 1024
    batch_size: 64
    max_steps: 5.0e5
    summary_freq: 1000
    time_horizon: 64

GridWorld:
    batch_size: 32
    normalize: false
    num_layers: 1
    hidden_units: 256
    beta: 5.0e-3
    buffer_size: 256
    max_steps: 50000
    summary_freq: 2000
    time_horizon: 5
    reward_signals:
        extrinsic:
            strength: 1.0
            gamma: 0.9

Basic:
    batch_size: 32
    normalize: false
    num_layers: 1
    hidden_units: 20
    beta: 5.0e-3
    buffer_size: 256
    max_steps: 5.0e5
    summary_freq: 2000
    time_horizon: 3
    reward_signals:
        extrinsic:
            strength: 1.0
            gamma: 0.9
